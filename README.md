This repository contains the complete pipeline for fine-tuning and evaluating Large Language Models (LLMs) for cross-lingual humor generation. The project focuses on adapting 
Gemma-2-2B and Qwen 2.5 7B models to generate jokes across English, Chinese, and Spanish.
Repo Structure
Model tuning: It contains two folders Gemma_Model and Qwen_model containing the code for fine tuniing these LLM Models.

evaluation and analysis: Code for assessing model performance.



